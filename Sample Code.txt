import ToxicityDetector from "@/components/ToxicityDetector";
import { Shield } from "lucide-react";

const Index = () => {
  return (
    <div className="min-h-screen bg-gradient-to-b from-background via-[#0a0a0a] to-background relative overflow-hidden">
      {/* Batman-style background effects */}
      <div className="absolute inset-0 bg-[radial-gradient(ellipse_at_top,_var(--tw-gradient-stops))] from-primary/5 via-transparent to-transparent" />
      <div className="absolute top-0 left-1/2 -translate-x-1/2 w-[800px] h-[800px] bg-primary/5 rounded-full blur-[150px] animate-pulse" />
      
      <div className="container mx-auto px-4 py-12 relative z-10">
        {/* Header */}
        <header className="text-center mb-12 animate-fade-in">
          <div className="flex items-center justify-center gap-3 mb-6">
            <div className="relative">
              <div className="absolute inset-0 bg-primary blur-2xl opacity-50 animate-pulse" />
              <div className="relative p-4 rounded-lg bg-card border-2 border-primary shadow-[0_0_30px_hsl(45_100%_51%/0.3)]">
                <Shield className="w-12 h-12 text-primary" />
              </div>
            </div>
          </div>
          <h1 className="text-6xl md:text-7xl font-black mb-4 text-primary tracking-wider uppercase drop-shadow-[0_0_20px_hsl(45_100%_51%/0.5)]">
            Cyberbullying Detector
          </h1>
          <div className="flex items-center justify-center gap-2 mb-4">
            <div className="h-px w-16 bg-gradient-to-r from-transparent to-primary" />
            <p className="text-xl text-foreground font-semibold tracking-wide">
              JUSTICE PROTECTION SYSTEM
            </p>
            <div className="h-px w-16 bg-gradient-to-l from-transparent to-primary" />
          </div>
          <p className="text-base text-muted-foreground max-w-2xl mx-auto font-medium">
            Analyze comments in real-time to identify toxic, harmful, or bullying content
          </p>
        </header>

        {/* Main Content */}
        <main className="animate-fade-in" style={{ animationDelay: "0.2s" }}>
          <ToxicityDetector />
        </main>

        {/* Footer */}
        <footer className="text-center mt-16 pb-8 animate-fade-in" style={{ animationDelay: "0.4s" }}>
          <div className="max-w-2xl mx-auto">
            <div className="h-px bg-gradient-to-r from-transparent via-primary/30 to-transparent mb-6" />
            <p className="text-sm text-primary/80 font-semibold tracking-wide uppercase">
              Developed as a Mini Project using LLM-based Toxic Comment Detection System
            </p>
            <p className="text-xs text-muted-foreground mt-2 font-medium">
              POWERED BY ADVANCED MACHINE LEARNING & NLP
            </p>
          </div>
        </footer>
      </div>
    </div>
  );
};

export default Index;
